{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Getting the MNIST data and storing it in ./MNIST_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32 # Number of images to run at each batch\n",
    "learning_rate = 0.03 # Learning rate for optimizer\n",
    "logdir = './logs/dcgan_mnist/' # Logdir for tensorboard summaries\n",
    "num_adversarial_iter = 1000000 # Number of epochs for the adversarial training\n",
    "num_discriminator_iter = 1000 # Number of epochs to pretrain the discriminator\n",
    "pkeep = 0.75 # Probability with which to keep nodes\n",
    "print_all = False # Print all tensor names and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to create convolutional and fully connected layers with tensorboard summaries\n",
    "\n",
    "def conv_layer(input, kernel_size, channels_in, channels_out, stride, name, reuse_variables=None):\n",
    "    with tf.variable_scope(name, reuse=reuse_variables):\n",
    "        # Defining the graph of the operation\n",
    "        w = tf.get_variable('weights', [kernel_size, kernel_size, channels_in, channels_out], \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('biases', [channels_out], initializer=tf.truncated_normal_initializer(stddev=0.01))      \n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, stride, stride, 1], padding=\"SAME\")      \n",
    "        act = tf.nn.elu(conv + b, name='activation') \n",
    "        \n",
    "        # Creating summaries for Tensorboard\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        \n",
    "        # Printing operation names and shapes for debugging\n",
    "        global print_all\n",
    "        if print_all:\n",
    "            print(w.name, w.shape)            \n",
    "            print(b.name, b.shape)\n",
    "            print(conv.name, conv.shape)\n",
    "            print(act.name, act.shape)\n",
    "            \n",
    "        return act\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name, activation, reuse_variables=None):\n",
    "    with tf.variable_scope(name, reuse=reuse_variables):\n",
    "        # Defining the graph of the operation\n",
    "        w = tf.get_variable('weights', [size_in, size_out], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('biases', [size_out], initializer=tf.truncated_normal_initializer(stddev=0.01)) \n",
    "        logit = tf.matmul(input, w) + b\n",
    "        \n",
    "        # Creating summaries for Tensorboard\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        \n",
    "        # Printing operation names and shapes for debugging\n",
    "        global print_all\n",
    "        if print_all:\n",
    "            print(w.name, w.shape)            \n",
    "            print(b.name, b.shape)\n",
    "            print(logit.name, logit.shape)\n",
    "        \n",
    "        # Covering the different cases needed\n",
    "        if activation == 'linear':\n",
    "            tf.summary.histogram(\"activations\", logit)\n",
    "            return logit\n",
    "        elif activation == 'elu':\n",
    "            act = tf.nn.elu(logit, name='activation')\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "            if print_all:\n",
    "                   print(act.name, act.shape)\n",
    "                    \n",
    "            return act\n",
    "    \n",
    "def deconv_layer(input, kernel_size, channels_in, channels_out, stride, name, activation, reuse_variables=None):\n",
    "    input_shape = input.get_shape().as_list()\n",
    "    with tf.variable_scope(name, reuse=reuse_variables):\n",
    "        # Defining the graph of the operation\n",
    "        w = tf.get_variable('weights', [kernel_size, kernel_size, channels_out, channels_in], \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('biases', [channels_out], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        conv = tf.nn.conv2d_transpose(input, w, \n",
    "                                      output_shape=[input_shape[0], input_shape[1]*stride, input_shape[2]*stride, channels_out], \n",
    "                                      strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "        \n",
    "        # Creating summaries for Tensorboard\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        \n",
    "        # Printing operation names and shapes for debugging\n",
    "        global print_all\n",
    "        if print_all:\n",
    "            print(w.name, w.shape)\n",
    "            print(b.name, b.shape)\n",
    "            print(conv.name, conv.shape)\n",
    "            \n",
    "        # Covering the different cases needed\n",
    "        if activation == 'elu':\n",
    "            act = tf.nn.elu(conv + b, name='activation')\n",
    "            if print_all:\n",
    "                print(act.name, act.shape)\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "            return act\n",
    "        elif activation == 'sigmoid':\n",
    "            act = tf.nn.sigmoid(conv + b, name='activation')\n",
    "            if print_all:\n",
    "                print(act.name, act.shape)\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "            return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the discriminator\n",
    "\n",
    "# input: [batch_size, 28, 28, 1]\n",
    "# output: [batch_size, 1]\n",
    "\n",
    "# 2 convolutional layers: input_shape = [-1, 28, 28, 1], output_shape = [-1, 7, 7, 64]\n",
    "# - Conv1: 32 5x5 filters, stride 2x2, padding = same, input_shape = [-1, 28, 28, 1]\n",
    "#   - weights: shape = [5, 5, 1, 32], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [32], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.elu\n",
    "# - Conv2: 64 5x5 filters, stride 2x2, padding = same, input_shape = [-1, 14, 14, 64]\n",
    "#   - weights: shape = [5, 5, 32, 64], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [64], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.elu\n",
    "# Reshape into vectors: input_shape = [-1, 7, 7, 64], output_shape = [-1, 7 * 7 * 64]\n",
    "# 3 fully connected layers: input_shape = [-1, 3136], output_shape = [-1, 1]\n",
    "# - FC1: input_shape = [-1, 3136]\n",
    "#   - weights: shape = [3136, 1024], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1024], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# - FC2: input_shape = [-1, 1024]\n",
    "#   - weights: shape = [1024, 128], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [128], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# - FC3: input_shape = [-1, 128]\n",
    "#   - weights: shape = [128, 1], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: linear\n",
    "\n",
    "# Loss: tf.sigmoid_cross_entropy_with_logits\n",
    "# Optimizer: tf.train.AdamOptimizer\n",
    "\n",
    "def discriminator(images, reuse_variables=None):\n",
    "    if not reuse_variables:\n",
    "        print('Initializing Discriminator')\n",
    "    else:\n",
    "        print('Reusing Discriminator')\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables):\n",
    "        d_conv_1 = conv_layer(input=images, kernel_size=5, channels_in=1, channels_out= 32, stride=2,\n",
    "                                    name='discriminator_conv_1', reuse_variables=reuse_variables)\n",
    "        d_conv_2 = conv_layer(input=d_conv_1, kernel_size=5, channels_in=32, channels_out= 64, stride=2,\n",
    "                                    name='discriminator_conv_2', reuse_variables=reuse_variables)\n",
    "        flattened = tf.reshape(d_conv_2, [-1, 7*7*64])\n",
    "        d_fc_1 = fc_layer(input=flattened, size_in=7*7*64, size_out=1024, activation='elu', name='discriminator_fc_1',\n",
    "                          reuse_variables=reuse_variables)\n",
    "        d_fc_2 = fc_layer(input=d_fc_1, size_in=1024, size_out=128, activation='elu', name='discriminator_fc_2',\n",
    "                          reuse_variables=reuse_variables)\n",
    "        d_fc_3 = fc_layer(input=d_fc_2, size_in=128, size_out=1, activation='linear', name='discriminator_fc_3',\n",
    "                          reuse_variables=reuse_variables)\n",
    "        return d_fc_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the generator\n",
    "\n",
    "# input: [batch_size, 128]\n",
    "# output: [batch_size, 28, 28, 1]\n",
    "\n",
    "# 2 fully connected layers: input_shape = [-1, 128], output_shape = [-1, 7 * 7 * 64]\n",
    "# - FC1: input_shape = [-1, 128], output_shape = [-1, 1024]\n",
    "#   - weights: shape = [128, 1024], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1024], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# - FC2: input_shape = [-1, 1024], output_shape = [-1, 7 * 7 * 128]\n",
    "#   - weights: shape = [1024, 7 * 7 * 64], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [7 * 7 * 64], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# Reshape data: input_shape = [-1,7*7*64] output_shape = [-1, 7, 7, 64]\n",
    "# 2 transpose convolution layers: input_shape = [-1, 7, 7, 64], output_shape = [-1, 28, 28, 1]\n",
    "# - Transpose_Conv1: input_shape = [-1, 7, 7, 64], output_shape = [-1, 14, 14, 32]\n",
    "#   - weights: shape = [5, 5, 64, 32], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [64], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.elu\n",
    "# - Transpose_Conv2: input_shape = [-1, 14, 14, 32], output_shape = [-1, 28, 28, 1]\n",
    "#   - weights: shape = [5, 5, 32, 1], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.sigmoid\n",
    "\n",
    "# Loss: tf.sigmoid_cross_entropy_with_logits\n",
    "# Optimizer: tf.train.AdamOptimizer\n",
    "\n",
    "def generator(z, reuse_variables=None):\n",
    "    if not reuse_variables:\n",
    "        print('Initializing Generator')\n",
    "    else:\n",
    "        print('Reusing Generator')\n",
    "    with tf.variable_scope(tf.get_variable_scope()):\n",
    "        g_fc_1 = fc_layer(input=z, size_in=128, size_out=1024, activation='elu', name='generator_fc_1', \n",
    "                          reuse_variables=reuse_variables)\n",
    "        g_fc_2 = fc_layer(input=g_fc_1, size_in=1024, size_out=7*7*64, activation='elu', name='generator_fc_2', \n",
    "                          reuse_variables=reuse_variables)\n",
    "        reshaped = tf.reshape(g_fc_2, [-1, 7, 7, 64])\n",
    "        g_deconv_1 = deconv_layer(input=reshaped, kernel_size=5, channels_in=64, channels_out= 32, stride=2,\n",
    "                                        name='generator_deconv_1', activation='elu', reuse_variables=reuse_variables)\n",
    "        g_deconv_2 = deconv_layer(input=g_deconv_1, kernel_size=5, channels_in=32, channels_out= 1, stride=2,\n",
    "                                        name='generator_deconv_2', activation='sigmoid', reuse_variables=reuse_variables)\n",
    "        return g_deconv_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith print_all = True:\\n    const = tf.constant(0, shape=[28*28, 128], dtype=tf.float32)\\n    gen = generator(const)\\n    reshaped_const = tf.reshape(const, [-1, 28, 28, 1])\\n    discrim1 = discriminator(reshaped_const)\\n    discrim2 = discriminator(reshaped_const, True)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing that the graphs work as intended\n",
    "# Using a constant zero vector of the correct shape to get the resulting tensors and their shapes\n",
    "\n",
    "#with print_all = True:\n",
    "#    const = tf.constant(0, shape=[28*28, 128], dtype=tf.float32)\n",
    "#    gen = generator(const)\n",
    "#    reshaped_const = tf.reshape(const, [-1, 28, 28, 1])\n",
    "#    discrim1 = discriminator(reshaped_const)\n",
    "#    discrim2 = discriminator(reshaped_const, True)\n",
    "\n",
    "\n",
    "# Print the nodes in the graph\n",
    "#[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Generator\n",
      "Initializing Discriminator\n",
      "Reusing Discriminator\n"
     ]
    }
   ],
   "source": [
    "# Defining the graphs, loss, optimizers, and summaries\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Creating placeholders for input to graph\n",
    "z_placeholder = tf.placeholder(tf.float32, [batch_size, 128], name = 'z_placeholder')\n",
    "images_placeholder = tf.placeholder(tf.float32, [batch_size, 28, 28, 1], name = 'images_placeholder')\n",
    "tf.summary.image('Input_images', images_placeholder, 6)\n",
    "\n",
    "# Initializing Generator and Discriminators\n",
    "Generator = generator(z_placeholder)\n",
    "Discriminator_real = discriminator(images_placeholder)\n",
    "Discriminator_fake = discriminator(Generator, reuse_variables=True)\n",
    "\n",
    "# Defining loss functions for networks\n",
    "with tf.name_scope('Cross Entropy'):\n",
    "    D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Discriminator_real, \n",
    "                                                                         labels=tf.ones_like(Discriminator_real)))\n",
    "    D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Discriminator_fake, \n",
    "                                                                         labels=tf.zeros_like(Discriminator_fake)))\n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Discriminator_fake, \n",
    "                                                                    labels=tf.ones_like(Discriminator_fake)))\n",
    "    tf.summary.scalar('D_loss_real', D_loss_real)\n",
    "    tf.summary.scalar('D_loss_fake', D_loss_fake)\n",
    "    tf.summary.scalar('G_loss', G_loss)\n",
    "\n",
    "# Getting the variables for each network to update only certain weights during each optimization\n",
    "tvars = tf.trainable_variables()\n",
    "D_vars = [var for var in tvars if 'discriminator_' in var.name]\n",
    "G_vars = [var for var in tvars if 'generator_' in var.name]\n",
    "\n",
    "# Defining the optimizer (Adam adaptive learning rate and momemtum optimizer)\n",
    "with tf.name_scope('Train'):\n",
    "    D_train_real = tf.train.AdamOptimizer(learning_rate).minimize(D_loss_real, var_list=D_vars)\n",
    "    D_train_fake = tf.train.AdamOptimizer(learning_rate).minimize(D_loss_fake, var_list=D_vars)\n",
    "    G_train_real = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=G_vars\n",
    "                                                                  \n",
    "# Defining graph for generating a sample image\n",
    "z_sample = tf.placeholder(dtype = tf.float32, shape = [6, 128], name='z_sample')\n",
    "sample_image = generator(z_sample, True)\n",
    "tf.summary.image('Generated_images', sample_images, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing Generator\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128cd0208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary merging and writing\n",
    "saver = tf.train.Saver()\n",
    "summ = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(logdir + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\")\n",
    "writer.add_graph(sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Define Tensorflow session and intialize variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Generate a sample image before training\n",
    "image = sess.run(sample_image, feed_dict={z_sample: np.random.normal(-1,1,[6,128])})\n",
    "plt.imshow(image[0].squeeze(), cmap='gray_r') # Squeeze the output of the generator down to two dimensions\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pretraining for discriminator\n",
    "for i in range(num_discrimator_iter):\n",
    "    image_batch = mnist.train.next_batch(batch_size)\n",
    "    z_input = np.random.normal(-1, 1, [batch_size, 128])\n",
    "    \n",
    "    sess.run([D_train_real, D_train_fake], feed_dict={images_placeholder: image_batch[0],\n",
    "                                                      z_placeholder: z_input})\n",
    "    if i % 100 == 0:\n",
    "        real_loss, fake_loss = sess.run([D_loss_real, D_train_fake], feed_dict={x: image_batch[0],\n",
    "                                                                                z_placeholder: z_input})\n",
    "        print(i, real_loss, fake_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train networks together\n",
    "\n",
    "for i in range(num_adversarial_iter):\n",
    "    image_batch = mnist.train.next_batch(batch_size)\n",
    "    z_input = np.random.normal(-1, 1, [batch_size, 128])\n",
    "    \n",
    "    sess.run([D_train_real, D_train_fake, G_train], feed_dict={images_placeholder: image_batch[0],\n",
    "                                                               z_placeholder: z_input})\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        s = sess.run(summ, {z_placeholder: z_input, x_placeholder: image_batch})\n",
    "        writer.add_summary(s, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "## https://github.com/jonbruner/generative-adversarial-networks\n",
    "## https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
