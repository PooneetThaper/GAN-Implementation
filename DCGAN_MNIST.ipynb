{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Getting the MNIST data and storing it in ./MNIST_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32 # Number of images to run at each batch\n",
    "learning_rate = 0.03 # Learning rate for optimizer\n",
    "logdir = './logs/dcgan_mnist/' # Logdir for tensorboard summaries\n",
    "num_adversarial_iter = 1000000 # Number of epochs for the adversarial training\n",
    "num_discriminator_iter = 1000 # Number of epochs to pretrain the discriminator\n",
    "pkeep = 0.75 # Probability with which to keep nodes\n",
    "print_all = False # Print all tensor names and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to create convolutional and fully connected layers with tensorboard summaries\n",
    "\n",
    "def conv_layer(input, kernel_size, channels_in, channels_out, stride, name, reuse_variables=None):\n",
    "    with tf.variable_scope(name, reuse=reuse_variables):\n",
    "        # Defining the graph of the operation\n",
    "        w = tf.get_variable('weights', [kernel_size, kernel_size, channels_in, channels_out], \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('biases', [channels_out], initializer=tf.truncated_normal_initializer(stddev=0.01))      \n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, stride, stride, 1], padding=\"SAME\")      \n",
    "        act = tf.nn.elu(conv + b, name='activation') \n",
    "        \n",
    "        # Creating summaries for Tensorboard\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        \n",
    "        # Printing operation names and shapes for debugging\n",
    "        global print_all\n",
    "        if print_all:\n",
    "            print(w.name, w.shape)            \n",
    "            print(b.name, b.shape)\n",
    "            print(conv.name, conv.shape)\n",
    "            print(act.name, act.shape)\n",
    "            \n",
    "        return act\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name, activation, reuse_variables=None):\n",
    "    with tf.variable_scope(name, reuse=reuse_variables):\n",
    "        # Defining the graph of the operation\n",
    "        w = tf.get_variable('weights', [size_in, size_out], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('biases', [size_out], initializer=tf.truncated_normal_initializer(stddev=0.01)) \n",
    "        logit = tf.matmul(input, w) + b\n",
    "        \n",
    "        # Creating summaries for Tensorboard\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        \n",
    "        # Printing operation names and shapes for debugging\n",
    "        global print_all\n",
    "        if print_all:\n",
    "            print(w.name, w.shape)            \n",
    "            print(b.name, b.shape)\n",
    "            print(logit.name, logit.shape)\n",
    "        \n",
    "        # Covering the different cases needed\n",
    "        if activation == 'linear':\n",
    "            tf.summary.histogram(\"activations\", logit)\n",
    "            return logit\n",
    "        elif activation == 'elu':\n",
    "            act = tf.nn.elu(logit, name='activation')\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "            if print_all:\n",
    "                   print(act.name, act.shape)\n",
    "                    \n",
    "            return act\n",
    "    \n",
    "def deconv_layer(input, kernel_size, channels_in, channels_out, stride, name, activation, reuse_variables=None):\n",
    "    input_shape = input.get_shape().as_list()\n",
    "    with tf.variable_scope(name, reuse=reuse_variables):\n",
    "        # Defining the graph of the operation\n",
    "        w = tf.get_variable('weights', [kernel_size, kernel_size, channels_out, channels_in], \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('biases', [channels_out], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        conv = tf.nn.conv2d_transpose(input, w, \n",
    "                                      output_shape=[input_shape[0], input_shape[1]*stride, input_shape[2]*stride, channels_out], \n",
    "                                      strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "        \n",
    "        # Creating summaries for Tensorboard\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        \n",
    "        # Printing operation names and shapes for debugging\n",
    "        global print_all\n",
    "        if print_all:\n",
    "            print(w.name, w.shape)\n",
    "            print(b.name, b.shape)\n",
    "            print(conv.name, conv.shape)\n",
    "            \n",
    "        # Covering the different cases needed\n",
    "        if activation == 'elu':\n",
    "            act = tf.nn.elu(conv + b, name='activation')\n",
    "            if print_all:\n",
    "                print(act.name, act.shape)\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "            return act\n",
    "        elif activation == 'sigmoid':\n",
    "            act = tf.nn.sigmoid(conv + b, name='activation')\n",
    "            if print_all:\n",
    "                print(act.name, act.shape)\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "            return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the discriminator\n",
    "\n",
    "# input: [batch_size, 28, 28, 1]\n",
    "# output: [batch_size, 1]\n",
    "\n",
    "# 2 convolutional layers: input_shape = [-1, 28, 28, 1], output_shape = [-1, 7, 7, 64]\n",
    "# - Conv1: 32 5x5 filters, stride 2x2, padding = same, input_shape = [-1, 28, 28, 1]\n",
    "#   - weights: shape = [5, 5, 1, 32], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [32], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.elu\n",
    "# - Conv2: 64 5x5 filters, stride 2x2, padding = same, input_shape = [-1, 14, 14, 64]\n",
    "#   - weights: shape = [5, 5, 32, 64], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [64], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.elu\n",
    "# Reshape into vectors: input_shape = [-1, 7, 7, 64], output_shape = [-1, 7 * 7 * 64]\n",
    "# 3 fully connected layers: input_shape = [-1, 3136], output_shape = [-1, 1]\n",
    "# - FC1: input_shape = [-1, 3136]\n",
    "#   - weights: shape = [3136, 1024], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1024], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# - FC2: input_shape = [-1, 1024]\n",
    "#   - weights: shape = [1024, 128], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [128], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# - FC3: input_shape = [-1, 128]\n",
    "#   - weights: shape = [128, 1], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: linear\n",
    "\n",
    "# Loss: tf.sigmoid_cross_entropy_with_logits\n",
    "# Optimizer: tf.train.AdamOptimizer\n",
    "\n",
    "def discriminator(images, reuse_variables=None):\n",
    "    if not reuse_variables:\n",
    "        print('Initializing Discriminator')\n",
    "    else:\n",
    "        print('Reusing Discriminator')\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables):\n",
    "        d_conv_1 = conv_layer(input=images, kernel_size=5, channels_in=1, channels_out= 32, stride=2,\n",
    "                                    name='discriminator_conv_1', reuse_variables=reuse_variables)\n",
    "        d_conv_2 = conv_layer(input=d_conv_1, kernel_size=5, channels_in=32, channels_out= 64, stride=2,\n",
    "                                    name='discriminator_conv_2', reuse_variables=reuse_variables)\n",
    "        flattened = tf.reshape(d_conv_2, [-1, 7*7*64])\n",
    "        d_fc_1 = fc_layer(input=flattened, size_in=7*7*64, size_out=1024, activation='elu', name='discriminator_fc_1',\n",
    "                          reuse_variables=reuse_variables)\n",
    "        d_fc_2 = fc_layer(input=d_fc_1, size_in=1024, size_out=128, activation='elu', name='discriminator_fc_2',\n",
    "                          reuse_variables=reuse_variables)\n",
    "        d_fc_3 = fc_layer(input=d_fc_2, size_in=128, size_out=1, activation='linear', name='discriminator_fc_3',\n",
    "                          reuse_variables=reuse_variables)\n",
    "        return d_fc_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the generator\n",
    "\n",
    "# input: [batch_size, 128]\n",
    "# output: [batch_size, 28, 28, 1]\n",
    "\n",
    "# 2 fully connected layers: input_shape = [-1, 128], output_shape = [-1, 7 * 7 * 64]\n",
    "# - FC1: input_shape = [-1, 128], output_shape = [-1, 1024]\n",
    "#   - weights: shape = [128, 1024], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1024], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# - FC2: input_shape = [-1, 1024], output_shape = [-1, 7 * 7 * 128]\n",
    "#   - weights: shape = [1024, 7 * 7 * 64], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [7 * 7 * 64], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# Reshape data: input_shape = [-1,7*7*64] output_shape = [-1, 7, 7, 64]\n",
    "# 2 transpose convolution layers: input_shape = [-1, 7, 7, 64], output_shape = [-1, 28, 28, 1]\n",
    "# - Transpose_Conv1: input_shape = [-1, 7, 7, 64], output_shape = [-1, 14, 14, 32]\n",
    "#   - weights: shape = [5, 5, 64, 32], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [64], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.elu\n",
    "# - Transpose_Conv2: input_shape = [-1, 14, 14, 32], output_shape = [-1, 28, 28, 1]\n",
    "#   - weights: shape = [5, 5, 32, 1], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.sigmoid\n",
    "\n",
    "# Loss: tf.sigmoid_cross_entropy_with_logits\n",
    "# Optimizer: tf.train.AdamOptimizer\n",
    "\n",
    "def generator(z, reuse_variables=None):\n",
    "    if not reuse_variables:\n",
    "        print('Initializing Generator')\n",
    "    else:\n",
    "        print('Reusing Generator')\n",
    "    with tf.variable_scope(tf.get_variable_scope()):\n",
    "        g_fc_1 = fc_layer(input=z, size_in=128, size_out=1024, activation='elu', name='generator_fc_1', \n",
    "                          reuse_variables=reuse_variables)\n",
    "        g_fc_2 = fc_layer(input=g_fc_1, size_in=1024, size_out=7*7*64, activation='elu', name='generator_fc_2', \n",
    "                          reuse_variables=reuse_variables)\n",
    "        reshaped = tf.reshape(g_fc_2, [-1, 7, 7, 64])\n",
    "        g_deconv_1 = deconv_layer(input=reshaped, kernel_size=5, channels_in=64, channels_out= 32, stride=2,\n",
    "                                        name='generator_deconv_1', activation='elu', reuse_variables=reuse_variables)\n",
    "        g_deconv_2 = deconv_layer(input=g_deconv_1, kernel_size=5, channels_in=32, channels_out= 1, stride=2,\n",
    "                                        name='generator_deconv_2', activation='sigmoid', reuse_variables=reuse_variables)\n",
    "        return g_deconv_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing that the graphs work as intended\n",
    "# Using a constant zero vector of the correct shape to get the resulting tensors and their shapes\n",
    "\n",
    "#with print_all = True:\n",
    "#    const = tf.constant(0, shape=[28*28, 128], dtype=tf.float32)\n",
    "#    gen = generator(const)\n",
    "#    reshaped_const = tf.reshape(const, [-1, 28, 28, 1])\n",
    "#    discrim1 = discriminator(reshaped_const)\n",
    "#    discrim2 = discriminator(reshaped_const, True)\n",
    "\n",
    "\n",
    "# Print the nodes in the graph\n",
    "#[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Generator\n",
      "Initializing Discriminator\n",
      "Reusing Discriminator\n",
      "Reusing Generator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Generated_images:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the graphs, loss, optimizers, and summaries\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Creating placeholders for input to graph\n",
    "z_placeholder = tf.placeholder(tf.float32, [batch_size, 128], name = 'z_placeholder')\n",
    "images_placeholder = tf.placeholder(tf.float32, [batch_size, 784], name = 'images_placeholder')\n",
    "images_reshaped = tf.reshape(images_placeholder, [-1, 28, 28, 1])\n",
    "tf.summary.image('Input_images', images_reshaped, 6)\n",
    "\n",
    "# Initializing Generator and Discriminators\n",
    "Generator = generator(z_placeholder)\n",
    "Discriminator_real = discriminator(images_reshaped)\n",
    "Discriminator_fake = discriminator(Generator, reuse_variables=True)\n",
    "\n",
    "# Defining loss functions for networks\n",
    "with tf.name_scope('Cross_Entropy'):\n",
    "    D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Discriminator_real, \n",
    "                                                                         labels=tf.zeros_like(Discriminator_real)))\n",
    "    D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Discriminator_fake, \n",
    "                                                                         labels=tf.ones_like(Discriminator_fake)))\n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Discriminator_fake, \n",
    "                                                                    labels=tf.zeros_like(Discriminator_fake)))\n",
    "    tf.summary.scalar('D_loss_real', D_loss_real)\n",
    "    tf.summary.scalar('D_loss_fake', D_loss_fake)\n",
    "    tf.summary.scalar('G_loss', G_loss)\n",
    "\n",
    "# Getting the variables for each network to update only certain weights during each optimization\n",
    "tvars = tf.trainable_variables()\n",
    "D_vars = [var for var in tvars if 'discriminator_' in var.name]\n",
    "G_vars = [var for var in tvars if 'generator_' in var.name]\n",
    "\n",
    "# Defining the optimizer (Adam adaptive learning rate and momemtum optimizer)\n",
    "with tf.name_scope('Train'):\n",
    "    D_train_real = tf.train.AdamOptimizer(learning_rate).minimize(D_loss_real, var_list=D_vars)\n",
    "    D_train_fake = tf.train.AdamOptimizer(learning_rate).minimize(D_loss_fake, var_list=D_vars)\n",
    "    G_train = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=G_vars)\n",
    "                                                                  \n",
    "# Defining graph for generating a sample image\n",
    "z_sample = tf.placeholder(dtype = tf.float32, shape = [6, 128], name='z_sample')\n",
    "sample_images = generator(z_sample, True)\n",
    "tf.summary.image('Generated_images', sample_images, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAACaCAYAAADYUbuPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8f8Be78C/u98VqUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf12fc6cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Tensorflow session and intialize variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Summary merging and writing\n",
    "saver = tf.train.Saver()\n",
    "summ = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(logdir + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\")\n",
    "writer.add_graph(sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Generate a sample image before training\n",
    "image = sess.run(sample_images, feed_dict={z_sample: np.random.normal(-1,1,[6,128])})\n",
    "fig, ax = plt.subplots(1, 6, figsize = (15, 24))\n",
    "for i, a in enumerate(ax):\n",
    "    a.imshow(image[i].squeeze(), cmap='gray_r') # Squeeze the output of the generator down to two dimensions\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 5412.8\n",
      "100 2.69278e-05 3.90774\n",
      "200 8.90635e-08 3.91586e-06\n",
      "300 1.14839e-08 3.50839e-06\n",
      "400 7.74192e-08 3.14437e-06\n",
      "500 3.0109e-08 2.80425e-06\n",
      "600 1.69351e-07 2.50705e-06\n",
      "700 3.02123e-08 2.23975e-06\n",
      "800 1.38751e-08 2.01621e-06\n",
      "900 1.12225e-07 1.79915e-06\n"
     ]
    }
   ],
   "source": [
    "# Pretraining for discriminator\n",
    "for i in range(num_discriminator_iter):\n",
    "    image_batch = mnist.train.next_batch(batch_size)\n",
    "    z_input = np.random.normal(-1, 1, [batch_size, 128])\n",
    "    \n",
    "    sess.run([D_train_real, D_train_fake], feed_dict={images_placeholder: image_batch[0],\n",
    "                                                      z_placeholder: z_input})\n",
    "    if i % 100 == 0:\n",
    "        image_batch_val = mnist.train.next_batch(batch_size)\n",
    "        z_val = np.random.normal(-1, 1, [batch_size, 128])\n",
    "        \n",
    "        real_loss, fake_loss = sess.run([D_loss_real, D_loss_fake], feed_dict={images_placeholder: image_batch_val[0],\n",
    "                                                                                z_placeholder: z_val})\n",
    "        print(i, real_loss, fake_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAACaCAYAAADYUbuPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACYzP8CUxI9nKaQdWkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf7fcd98d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f686ad907426>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mimage_batch_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mz_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msumm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mz_placeholder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_placeholder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_batch_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_sample\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz_summary\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train networks together\n",
    "\n",
    "for i in range(num_adversarial_iter):\n",
    "    image_batch = mnist.train.next_batch(batch_size)\n",
    "    z_input = np.random.normal(-1, 1, [batch_size, 128])\n",
    "    \n",
    "    sess.run([D_train_real, D_train_fake, G_train], feed_dict={images_placeholder: image_batch[0],\n",
    "                                                               z_placeholder: z_input})\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        z_val = np.random.normal(-1, 1, [batch_size, 128])\n",
    "        image_batch_val = mnist.train.next_batch(batch_size)\n",
    "        z_summary = np.random.normal(-1, 1, [6, 128])\n",
    "        s = sess.run(summ, {z_placeholder: z_val, images_placeholder: image_batch_val[0], z_sample: z_summary})\n",
    "        writer.add_summary(s, i)\n",
    "        if i%10000 == 0:\n",
    "            image = sess.run(sample_images, feed_dict={z_sample: z_summary})\n",
    "            plt.close()\n",
    "            fig, ax = plt.subplots(1, 6, figsize = (15, 24))\n",
    "            for i, a in enumerate(ax):\n",
    "                a.imshow(image[i].squeeze(), cmap='gray_r') # Squeeze the output of the generator down to two dimensions\n",
    "            plt.show()\n",
    "    if i%1000 == 0:\n",
    "        z_test = np.random.normal(-1, 1, [batch_size, 128])\n",
    "        image_batch_test = mnist.train.next_batch(batch_size)\n",
    "        d_loss_real, d_loss_fake, g_loss = sess.run([D_loss_real, D_loss_fake, G_loss], \n",
    "                                                    feed_dict={images_placeholder: image_batch_test[0],\n",
    "                                                               z_placeholder: z_test})\n",
    "        print(i, d_loss_real, d_loss_fake, g_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "## https://github.com/jonbruner/generative-adversarial-networks\n",
    "## https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
